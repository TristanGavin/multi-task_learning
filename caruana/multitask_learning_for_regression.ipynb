{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5cdf24ee",
   "metadata": {},
   "source": [
    "# Motivating Coding Example\n",
    "\n",
    "From Richard Caruana's thesis paper on Multi-task learning \n",
    "\n",
    "## Tasks\n",
    "\n",
    "* Task 1 = $B1      \\vee Parity(B4-B8)$\n",
    "* Task 2 = $\\neg(B1) \\vee  Parity(B4-B8)$\n",
    "* Task 3 = $B1      \\wedge Parity(B4-B8)$\n",
    "* Task 4 = $\\neg(B1) \\wedge Parity(B4-B8)$\n",
    "\n",
    "example\n",
    "\n",
    "input: 10100101\n",
    "\n",
    "Task 1: $B1 == 1 \\vee Parity(B4-B8) \\rightarrow B1 == 1 \\rightarrow Task1 = True$\n",
    "\n",
    "Task 2: $B1 == 0 \\vee Parity(B4-B8) \\rightarrow B1 !=0 \\rightarrow Parity(B2-B8) = 2 \\rightarrow Task 2 = True$\n",
    "\n",
    "Task 3: $B1 == 1 \\wedge Parity(B4-B8) \\rightarrow True \\wedge True \\rightarrow Task 3 = True$\n",
    "\n",
    "Task 4: $B1 == 1 \\rightarrow Task 4 = False$\n",
    "\n",
    "### shared information between tasks\n",
    "\n",
    "We can see that there is shared information between tasks, for example Task 1 and Task 2 are both true (false) if the Parity of bits 4 through 8 is true (false). likewise task 3 and 4 are both false if the parity of bits 4 through 8 are false. Another signal we are hoping that is learned is to ignore bits 2 and 3.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e0679f31",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "from make_targets import getParity, get_data\n",
    "from model_training import train_model, test_model\n",
    "import os\n",
    "\n",
    "################################################################################################################################\n",
    "# DATASETS\n",
    "\n",
    "class BinaryDataset(Dataset):\n",
    "\n",
    "    def __init__(self, filename):\n",
    "        # data loading\n",
    "        df = pd.read_csv(filename) # bits 3, 4 don't matter\n",
    "        X = []\n",
    "        for i in range(256):\n",
    "            X.append([int(i) for i in str(format(i, '08b'))])\n",
    "\n",
    "        self.x = torch.FloatTensor(X)\n",
    "        self.y1 = torch.transpose(torch.FloatTensor([df['1'].to_numpy()]), 0, 1)\n",
    "        self.y2 = torch.transpose(torch.FloatTensor([df['2'].to_numpy()]), 0, 1)\n",
    "        self.y3 = torch.transpose(torch.FloatTensor([df['3'].to_numpy()]), 0, 1)\n",
    "        self.y4 = torch.transpose(torch.FloatTensor([df['4'].to_numpy()]), 0, 1) \n",
    "        self.num_samples = self.x.shape[0]\n",
    "\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.x[index], self.y1[index], self.y2[index], self.y3[index], self.y4[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.num_samples\n",
    "\n",
    "################################################################################################################################\n",
    "# MODEL CLASSES\n",
    "\n",
    "class MultiTask(nn.Module):\n",
    "\n",
    "    def __init__(self, num_targets):\n",
    "        super(MultiTask, self).__init__()\n",
    "        self.hidden1 = nn.Linear(8, 100)  # 8 input units 100 hidden units\n",
    "        self.hidden2 = nn.Linear(100, 20)\n",
    "        self.output = nn.Linear(20, num_targets)    # 1 output\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.hidden1(x))         # relu activation function for hidden layers\n",
    "        x = F.relu(self.hidden2(x)) \n",
    "        x = torch.sigmoid(self.output(x))   # sigmoid returns probability of being 1\n",
    "        return x  \n",
    "\n",
    "    \n",
    "################################################################################################################################\n",
    "# IMPORT DATA\n",
    "\n",
    "# format and shuffle data\n",
    "dataset = BinaryDataset('./targets2.csv')\n",
    "dataset_size = len(dataset)\n",
    "valid_split = 0.5\n",
    "random_seed = 46\n",
    "\n",
    "# Creating data indices for training and validation splits:\n",
    "indices = list(range(dataset_size))\n",
    "split = int(np.floor(valid_split * dataset_size))\n",
    "np.random.seed(random_seed)\n",
    "np.random.shuffle(indices)\n",
    "train_indices, val_indices = indices[split:], indices[:split]\n",
    "\n",
    "# Creating PT data samplers and loaders:\n",
    "train_sampler = SubsetRandomSampler(train_indices)\n",
    "valid_sampler = SubsetRandomSampler(val_indices)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset, batch_size=len(train_sampler), \n",
    "                                           sampler=train_sampler)\n",
    "validation_loader = torch.utils.data.DataLoader(dataset, batch_size=len(valid_sampler),\n",
    "                                                sampler=valid_sampler)\n",
    "dataloaders = [train_loader, validation_loader]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62219a99",
   "metadata": {},
   "source": [
    "# Training Procedure\n",
    "\n",
    "## Hyper Parameters\n",
    "\n",
    "* Train/Test split = .5/.5  \n",
    "\n",
    "* Epochs = 15000\n",
    "\n",
    "* Optimizer = SGD (stochastic gradient decent)\n",
    "\n",
    "* learning rate = 0.1\n",
    "\n",
    "For each model we will train and test the model 5 different times on shuffled data and report the average test accruacy over those 5 models. we are only testing on target 1 and are using all other targets as auxilary tasks to hopefully generalize the model learned.\n",
    "\n",
    "All models use the same hyper parameters and layer configuration\n",
    "\n",
    "\n",
    "###  STL\n",
    "\n",
    "### MTL tasks 1 and 2\n",
    "\n",
    "### MTL tasks 1 and 3 \n",
    "\n",
    "### MTL tasks 1, 2, 3 and 4\n",
    "\n",
    "--------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23d9af87",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "776aaefe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
