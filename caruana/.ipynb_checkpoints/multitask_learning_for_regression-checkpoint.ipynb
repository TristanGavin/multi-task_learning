{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3dc1501f",
   "metadata": {},
   "source": [
    "# Multi-task learning for regression\n",
    "\n",
    "## Motivation for MTL\n",
    "\n",
    "<img src=\"http://nicksenger.com/onecatholiclife/wp-content/uploads/2016/08/KarateKid_WaxOnWaxOff.jpg\" alt=\"drawing\" width=\"400\"/>\n",
    "\n",
    "Knowledge in one task can give insight and assist in learning another\n",
    "\n",
    "learning tasks in parrallel while using a shared representation\n",
    "\n",
    "### Insufficient Data\n",
    "\n",
    "### Form of regularization\n",
    "\n",
    "Multi-task learning works because regularization induced by requiring an algorithm to perform well on a related task can be superior to regularization that prevents overfitting by penalizing all complexity uniformly.\n",
    "\n",
    "### Reduced Training Time \n",
    "\n",
    "Instead of having to train many different models for each task we are able to train one model for all tasks.\n",
    "\n",
    "## Problems with MTL\n",
    "\n",
    "### negative transfer \n",
    "\n",
    "### dominating tasks\n",
    "\n",
    "### more complicated loss function\n",
    "\n",
    "as a result of multiple summed losses\n",
    "\n",
    "## MTL for Classification\n",
    "\n",
    "lots of examples. spam, computer vision, autonomous vehicles...\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cdf24ee",
   "metadata": {},
   "source": [
    "# Motivating Coding Example\n",
    "\n",
    "From Richard Caruana's thesis paper on Multi-task learning \n",
    "\n",
    "## Tasks\n",
    "\n",
    "* Task 1 = $B1      \\vee Parity(B2-B8)$\n",
    "* Task 2 = $\\neg(B1) \\vee  Parity(B2-B8)$\n",
    "* Task 3 = $B1      \\wedge Parity(B2-B8)$\n",
    "* Task 4 = $\\neg(B1) \\wedge Parity(B2-B8)$\n",
    "\n",
    "example\n",
    "\n",
    "input: 10100101\n",
    "\n",
    "Task 1: $B1 == 1 \\vee Parity(B2-B8) \\rightarrow B1 == 1 \\rightarrow Task1 = True$\n",
    "\n",
    "Task 2: $B1 == 0 \\vee Parity(B2-B8) \\rightarrow B1 !=0 \\rightarrow Parity(B2-B8) = 3 \\rightarrow Task 2 = False$\n",
    "\n",
    "Task 3: $B1 == 1 \\wedge Parity(B2-B8) \\rightarrow True \\wedge False \\rightarrow Task 3 = False$\n",
    "\n",
    "Task 4: $Parity(B2-B8) == False \\rightarrow Task 4 = False$\n",
    "\n",
    "### shared information between tasks\n",
    "\n",
    "We can see that there is shared information between tasks, for example Task 1 and Task 2 are both true (false) if the Parity of bits 2 through 8 is true (false). likewise task 3 and 4 are both false if the parity of bits 2 through 8 are false.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e0679f31",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "from make_targets import getParity, get_data\n",
    "from model_training import train_model, test_model\n",
    "\n",
    "################################################################################################################################\n",
    "# DEFINE DATASET\n",
    "\n",
    "class BinaryDataset(Dataset):\n",
    "    \n",
    "    def __init__(self):\n",
    "        # data loading\n",
    "        df = pd.read_csv('./targets.csv')\n",
    "        X = []\n",
    "        for i in range(256):\n",
    "            X.append([int(i) for i in str(format(i, '08b'))])\n",
    "\n",
    "        self.x = torch.FloatTensor(X)\n",
    "        self.y1 = torch.transpose(torch.FloatTensor([df['1'].to_numpy()]), 0, 1)\n",
    "        self.y2 = torch.transpose(torch.FloatTensor([df['2'].to_numpy()]), 0, 1)\n",
    "        self.y3 = torch.transpose(torch.FloatTensor([df['3'].to_numpy()]), 0, 1)\n",
    "        self.y4 = torch.transpose(torch.FloatTensor([df['4'].to_numpy()]), 0, 1) \n",
    "        self.num_samples = self.x.shape[0]\n",
    "\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.x[index], self.y1[index], self.y2[index], self.y3[index], self.y4[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.num_samples\n",
    "    \n",
    "################################################################################################################################\n",
    "# DEFINE MODEL\n",
    "\n",
    "class MultiTask(nn.Module):\n",
    "\n",
    "    def __init__(self, num_targets):\n",
    "        super(MultiTask, self).__init__()\n",
    "        self.hidden1 = nn.Linear(8, 100)  # 8 input units 160 hidden units\n",
    "        self.hidden2 = nn.Linear(100, 20)\n",
    "        self.output = nn.Linear(20, num_targets)    # 1 output\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.hidden1(x))         # relu activation function for hidden layers\n",
    "        x = F.relu(self.hidden2(x)) \n",
    "        x = torch.sigmoid(self.output(x))   # sigmoid returns probability of being 1\n",
    "        return x  \n",
    "    \n",
    "################################################################################################################################\n",
    "# IMPORT DATA\n",
    "\n",
    "# format and shuffle data\n",
    "dataset = BinaryDataset()\n",
    "dataset_size = len(dataset)\n",
    "valid_split = 0.2\n",
    "random_seed = 42\n",
    "\n",
    "# Creating data indices for training and validation splits:\n",
    "indices = list(range(dataset_size))\n",
    "split = int(np.floor(valid_split * dataset_size))\n",
    "np.random.seed(random_seed)\n",
    "np.random.shuffle(indices)\n",
    "train_indices, val_indices = indices[split:], indices[:split]\n",
    "\n",
    "# Creating PT data samplers and loaders:\n",
    "train_sampler = SubsetRandomSampler(train_indices)\n",
    "valid_sampler = SubsetRandomSampler(val_indices)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset, batch_size=len(train_sampler), \n",
    "                                           sampler=train_sampler)\n",
    "validation_loader = torch.utils.data.DataLoader(dataset, batch_size=len(valid_sampler),\n",
    "                                                sampler=valid_sampler)\n",
    "dataloaders = [train_loader, validation_loader]\n",
    "\n",
    "# initialize models\n",
    "single_task1 = MultiTask(1) # task 1 \n",
    "single_task2 = MultiTask(1) # task 2\n",
    "single_task3 = MultiTask(1) # task 3 \n",
    "single_task4 = MultiTask(1) # task 4\n",
    "    \n",
    "# train individual models\n",
    "print(\"training task 1 (single task learning): \")\n",
    "print(\"----------------------------------------------------\")\n",
    "train1_acc, test1_acc, target1_acc = train_model(single_task1, dataloaders, [1])\n",
    "make_graphs(train1_acc, test1_acc, target1_acc, \"task1_STL\")\n",
    "\n",
    "print(\"training task 2 (single task learning): \")\n",
    "print(\"----------------------------------------------------\")\n",
    "train2_acc, test2_acc, target2_acc = train_model(single_task2, dataloaders, [2])\n",
    "make_graphs(train2_acc, test2_acc, target2_acc, \"task2_STL\")\n",
    "\n",
    "print(\"training task 3 (single task learning): \")\n",
    "print(\"----------------------------------------------------\")\n",
    "train3_acc, test3_acc, target3_acc = train_model(single_task3, dataloaders, [3])\n",
    "make_graphs(train3_acc, test3_acc, target3_acc, \"task3_STL\")\n",
    "\n",
    "print(\"training task 4 (single task learning): \")\n",
    "print(\"----------------------------------------------------\")\n",
    "train4_acc, test4_acc, target4_acc = train_model(single_task4, dataloaders, [4])\n",
    "make_graphs(train4_acc, test4_acc, target4_acc, \"task4_STL\")\n",
    "\n",
    "# save models torch.save(model.state_dict()\n",
    "torch.save(single_task1.state_dict(), \"./models/single_task1.pth\") \n",
    "torch.save(single_task2.state_dict(), \"./models/single_task2.pth\") \n",
    "torch.save(single_task3.state_dict(), \"./models/single_task3.pth\") \n",
    "torch.save(single_task4.state_dict(), \"./models/single_task4.pth\") "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
